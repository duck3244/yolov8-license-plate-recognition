"""
realtime_processor.py
ì‹¤ì‹œê°„ ë²ˆí˜¸íŒ ì¸ì‹ ë° ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬

Author: License Plate Recognition Team
Date: 2025-08-29
Version: 2.0.0
"""

import cv2
import numpy as np
import threading
import queue
import time
from datetime import datetime
from typing import Optional, Callable, Dict, Any
import logging

from database_manager import DatabaseManager, PlateDetection

logger = logging.getLogger(__name__)

class RealTimeProcessor:
    """ì‹¤ì‹œê°„ ë²ˆí˜¸íŒ ì¸ì‹ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, 
                 recognizer, 
                 db_manager: DatabaseManager,
                 frame_skip: int = 10,
                 max_queue_size: int = 10):
        """
        ì‹¤ì‹œê°„ ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            recognizer: ë²ˆí˜¸íŒ ì¸ì‹ê¸° ê°ì²´
            db_manager: ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
            frame_skip: ì²˜ë¦¬í•  í”„ë ˆì„ ê°„ê²© (ì„±ëŠ¥ ìµœì í™”)
            max_queue_size: ìµœëŒ€ í í¬ê¸°
        """
        self.recognizer = recognizer
        self.db_manager = db_manager
        self.frame_skip = frame_skip
        
        # ìŠ¤ë ˆë”©ì„ ìœ„í•œ í
        self.frame_queue = queue.Queue(maxsize=max_queue_size)
        self.result_queue = queue.Queue()
        
        # ìƒíƒœ ê´€ë¦¬
        self.is_running = False
        self.frame_count = 0
        self.detection_count = 0
        
        # ìŠ¤ë ˆë“œ
        self.capture_thread = None
        self.processing_thread = None
        
        # ì½œë°± í•¨ìˆ˜ë“¤
        self.detection_callback = None
        self.frame_callback = None
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'fps': 0,
            'detection_rate': 0,
            'avg_processing_time': 0,
            'start_time': None
        }
    
    def set_detection_callback(self, callback: Callable[[PlateDetection, np.ndarray], None]):
        """
        íƒì§€ ê²°ê³¼ ì½œë°± í•¨ìˆ˜ ì„¤ì •
        
        Args:
            callback: (detection, frame) -> None í˜•íƒœì˜ ì½œë°± í•¨ìˆ˜
        """
        self.detection_callback = callback
    
    def set_frame_callback(self, callback: Callable[[np.ndarray], None]):
        """
        í”„ë ˆì„ ì²˜ë¦¬ ì½œë°± í•¨ìˆ˜ ì„¤ì •
        
        Args:
            callback: (frame) -> None í˜•íƒœì˜ ì½œë°± í•¨ìˆ˜
        """
        self.frame_callback = callback
    
    def start_camera_processing(self, camera_index: int = 0, resolution: tuple = (1280, 720)) -> bool:
        """
        ì¹´ë©”ë¼ë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œì‘
        
        Args:
            camera_index: ì¹´ë©”ë¼ ì¸ë±ìŠ¤
            resolution: í•´ìƒë„ (width, height)
            
        Returns:
            ì‹œì‘ ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.is_running = True
            self.stats['start_time'] = time.time()
            
            # ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘
            self.capture_thread = threading.Thread(
                target=self._capture_camera_frames,
                args=(camera_index, resolution),
                daemon=True
            )
            
            # ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
            self.processing_thread = threading.Thread(
                target=self._process_frames,
                daemon=True
            )
            
            self.capture_thread.start()
            self.processing_thread.start()
            
            logger.info(f"ğŸ¥ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ì²˜ë¦¬ ì‹œì‘ (ì¹´ë©”ë¼: {camera_index}, í•´ìƒë„: {resolution})")
            return True
            
        except Exception as e:
            logger.error(f"ì¹´ë©”ë¼ ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.is_running = False
            return False
    
    def start_video_processing(self, video_path: str) -> bool:
        """
        ë¹„ë””ì˜¤ íŒŒì¼ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œì‘
        
        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì‹œì‘ ì„±ê³µ ì—¬ë¶€
        """
        try:
            self.is_running = True
            self.stats['start_time'] = time.time()
            
            # ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘
            self.capture_thread = threading.Thread(
                target=self._capture_video_frames,
                args=(video_path,),
                daemon=True
            )
            
            # ì²˜ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘
            self.processing_thread = threading.Thread(
                target=self._process_frames,
                daemon=True
            )
            
            self.capture_thread.start()
            self.processing_thread.start()
            
            logger.info(f"ğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {video_path}")
            return True
            
        except Exception as e:
            logger.error(f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
            self.is_running = False
            return False
    
    def _capture_camera_frames(self, camera_index: int, resolution: tuple):
        """ì¹´ë©”ë¼ í”„ë ˆì„ ìº¡ì²˜"""
        cap = cv2.VideoCapture(camera_index)
        
        # ì¹´ë©”ë¼ ì„¤ì •
        width, height = resolution
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        cap.set(cv2.CAP_PROP_FPS, 30)
        
        if not cap.isOpened():
            logger.error(f"ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {camera_index}")
            self.is_running = False
            return
        
        logger.info(f"ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ: {cap.get(cv2.CAP_PROP_FRAME_WIDTH)}x{cap.get(cv2.CAP_PROP_FRAME_HEIGHT)}")
        
        frame_time = time.time()
        
        while self.is_running:
            ret, frame = cap.read()
            if not ret:
                logger.warning("ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                continue
            
            current_time = time.time()
            
            # FPS ê³„ì‚°
            if current_time - frame_time > 1.0:
                self.stats['fps'] = self.frame_count / (current_time - frame_time)
                self.frame_count = 0
                frame_time = current_time
            
            self.frame_count += 1
            
            # í”„ë ˆì„ ì½œë°± í˜¸ì¶œ
            if self.frame_callback:
                self.frame_callback(frame.copy())
            
            try:
                # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì´ì „ í”„ë ˆì„ ì œê±°
                if self.frame_queue.full():
                    try:
                        self.frame_queue.get_nowait()
                    except queue.Empty:
                        pass
                
                self.frame_queue.put((frame, current_time), timeout=0.1)
                
            except queue.Full:
                # íê°€ ê°€ë“ ì°¬ ê²½ìš° ìŠ¤í‚µ
                pass
            except Exception as e:
                logger.error(f"í”„ë ˆì„ í ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        
        cap.release()
        logger.info("ì¹´ë©”ë¼ ìº¡ì²˜ ì¢…ë£Œ")
    
    def _capture_video_frames(self, video_path: str):
        """ë¹„ë””ì˜¤ íŒŒì¼ í”„ë ˆì„ ìº¡ì²˜"""
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            logger.error(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            self.is_running = False
            return
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        logger.info(f"ë¹„ë””ì˜¤ ë¡œë“œ ì™„ë£Œ: {total_frames} í”„ë ˆì„, {fps} FPS")
        
        frame_interval = 1.0 / fps if fps > 0 else 1.0 / 30
        last_frame_time = time.time()
        
        while self.is_running:
            ret, frame = cap.read()
            if not ret:
                logger.info("ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ")
                self.is_running = False
                break
            
            current_time = time.time()
            
            # ì›ë³¸ FPSì— ë§ì¶° ì¬ìƒ
            elapsed = current_time - last_frame_time
            if elapsed < frame_interval:
                time.sleep(frame_interval - elapsed)
            
            self.frame_count += 1
            
            # í”„ë ˆì„ ì½œë°± í˜¸ì¶œ
            if self.frame_callback:
                self.frame_callback(frame.copy())
            
            try:
                if self.frame_queue.full():
                    try:
                        self.frame_queue.get_nowait()
                    except queue.Empty:
                        pass
                
                self.frame_queue.put((frame, current_time), timeout=0.1)
                
            except queue.Full:
                pass
            except Exception as e:
                logger.error(f"ë¹„ë””ì˜¤ í”„ë ˆì„ í ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            
            last_frame_time = current_time
        
        cap.release()
        logger.info("ë¹„ë””ì˜¤ ìº¡ì²˜ ì¢…ë£Œ")
    
    def _process_frames(self):
        """í”„ë ˆì„ ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
        processing_times = []
        
        while self.is_running:
            try:
                # í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 1ì´ˆ)
                frame_data = self.frame_queue.get(timeout=1.0)
                frame, capture_time = frame_data
                
                # í”„ë ˆì„ ìŠ¤í‚¤í•‘ (ì„±ëŠ¥ ìµœì í™”)
                if self.frame_count % self.frame_skip != 0:
                    continue
                
                start_time = time.time()
                
                # ë²ˆí˜¸íŒ íƒì§€
                plates = self.recognizer.detect_license_plates(frame)
                
                if plates:
                    # ê°€ì¥ ì‹ ë¢°ë„ê°€ ë†’ì€ ë²ˆí˜¸íŒ ì²˜ë¦¬
                    best_plate = max(plates, key=lambda x: x[4])
                    x1, y1, x2, y2, confidence = best_plate
                    
                    # ë²ˆí˜¸íŒ ì˜ì—­ ì¶”ì¶œ
                    plate_region = frame[y1:y2, x1:x2]
                    
                    # í…ìŠ¤íŠ¸ ì¸ì‹
                    plate_text = self.recognizer.recognize_text(plate_region)
                    
                    processing_time = time.time() - start_time
                    processing_times.append(processing_time)
                    
                    # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚° (ìµœê·¼ 100ê°œ)
                    if len(processing_times) > 100:
                        processing_times = processing_times[-100:]
                    
                    self.stats['avg_processing_time'] = np.mean(processing_times)
                    
                    if plate_text and len(plate_text.strip()) > 3:
                        self.detection_count += 1
                        
                        # íƒì§€ìœ¨ ê³„ì‚°
                        if self.stats['start_time']:
                            elapsed_time = time.time() - self.stats['start_time']
                            self.stats['detection_rate'] = self.detection_count / elapsed_time * 60  # ë¶„ë‹¹ íƒì§€ìˆ˜
                        
                        # íƒì§€ ê²°ê³¼ ê°ì²´ ìƒì„±
                        detection = PlateDetection(
                            plate_number=plate_text,
                            confidence=confidence,
                            timestamp=datetime.fromtimestamp(capture_time),
                            bbox=(x1, y1, x2, y2),
                            processing_time=processing_time
                        )
                        
                        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                        self.db_manager.save_detection(detection)
                        
                        # ê²°ê³¼ ì‹œê°í™”
                        result_frame = frame.copy()
                        cv2.rectangle(result_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
                        cv2.putText(result_frame, f"{plate_text} ({confidence:.2f})", 
                                   (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
                        
                        # íƒì§€ ì½œë°± í˜¸ì¶œ
                        if self.detection_callback:
                            self.detection_callback(detection, result_frame)
                        
                        # ê²°ê³¼ íì— ì¶”ê°€
                        try:
                            self.result_queue.put({
                                'frame': result_frame,
                                'detection': detection,
                                'timestamp': capture_time
                            }, timeout=0.1)
                        except queue.Full:
                            # íê°€ ê°€ë“ ì°¬ ê²½ìš° ì´ì „ ê²°ê³¼ ì œê±°
                            try:
                                self.result_queue.get_nowait()
                                self.result_queue.put({
                                    'frame': result_frame,
                                    'detection': detection,
                                    'timestamp': capture_time
                                })
                            except queue.Empty:
                                pass
                        
                        logger.debug(f"ë²ˆí˜¸íŒ íƒì§€: {plate_text} (ì‹ ë¢°ë„: {confidence:.3f})")
                
            except queue.Empty:
                # íƒ€ì„ì•„ì›ƒ - ì •ìƒì ì¸ ìƒí™©
                continue
            except Exception as e:
                logger.error(f"í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                time.sleep(0.1)
    
    def get_latest_result(self, timeout: float = 0.1) -> Optional[Dict[str, Any]]:
        """
        ìµœì‹  ì²˜ë¦¬ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)
            
        Returns:
            ìµœì‹  ì²˜ë¦¬ ê²°ê³¼ ë˜ëŠ” None
        """
        try:
            return self.result_queue.get(timeout=timeout)
        except queue.Empty:
            return None
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        ì‹¤ì‹œê°„ ì²˜ë¦¬ í†µê³„ ë°˜í™˜
        
        Returns:
            ì²˜ë¦¬ í†µê³„ ì •ë³´
        """
        stats = self.stats.copy()
        stats['detection_count'] = self.detection_count
        stats['frame_count'] = self.frame_count
        stats['is_running'] = self.is_running
        stats['queue_sizes'] = {
            'frame_queue': self.frame_queue.qsize(),
            'result_queue': self.result_queue.qsize()
        }
        
        return stats
    
    def stop_processing(self):
        """ì‹¤ì‹œê°„ ì²˜ë¦¬ ì¤‘ë‹¨"""
        if self.is_running:
            logger.info("ì‹¤ì‹œê°„ ì²˜ë¦¬ ì¤‘ë‹¨ ì¤‘...")
            self.is_running = False
            
            # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
            if self.capture_thread and self.capture_thread.is_alive():
                self.capture_thread.join(timeout=5.0)
            
            if self.processing_thread and self.processing_thread.is_alive():
                self.processing_thread.join(timeout=5.0)
            
            logger.info("ì‹¤ì‹œê°„ ì²˜ë¦¬ ì™„ì „ ì¤‘ë‹¨")

class StreamingServer:
    """ì›¹ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„"""
    
    def __init__(self, realtime_processor: RealTimeProcessor, port: int = 8080):
        self.realtime_processor = realtime_processor
        self.port = port
        self.is_running = False
        
    def start_streaming(self):
        """ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
        from flask import Flask, Response
        
        app = Flask(__name__)
        
        @app.route('/stream')
        def video_stream():
            """ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—”ë“œí¬ì¸íŠ¸"""
            return Response(
                self._generate_frames(),
                mimetype='multipart/x-mixed-replace; boundary=frame'
            )
        
        @app.route('/stream_info')
        def stream_info():
            """ìŠ¤íŠ¸ë¦¼ ì •ë³´ API"""
            stats = self.realtime_processor.get_statistics()
            return jsonify(stats)
        
        self.is_running = True
        logger.info(f"ğŸ”´ ìŠ¤íŠ¸ë¦¬ë° ì„œë²„ ì‹œì‘: http://localhost:{self.port}/stream")
        app.run(host='0.0.0.0', port=self.port, debug=False, threaded=True)
    
    def _generate_frames(self):
        """í”„ë ˆì„ ìƒì„±ê¸°"""
        while self.is_running and self.realtime_processor.is_running:
            result = self.realtime_processor.get_latest_result(timeout=1.0)
            
            if result:
                frame = result['frame']
                
                # JPEGë¡œ ì¸ì½”ë”©
                ret, buffer = cv2.imencode('.jpg', frame, 
                                         [cv2.IMWRITE_JPEG_QUALITY, 80])
                
                if ret:
                    frame_bytes = buffer.tobytes()
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            else:
                # ë¹ˆ í”„ë ˆì„ ì „ì†¡
                time.sleep(0.1)
    
    def stop_streaming(self):
        """ìŠ¤íŠ¸ë¦¬ë° ì¤‘ë‹¨"""
        self.is_running = False

class WebcamViewer:
    """ì›¹ìº  ì‹¤ì‹œê°„ ë·°ì–´ (OpenCV ìœˆë„ìš°)"""
    
    def __init__(self, realtime_processor: RealTimeProcessor):
        self.realtime_processor = realtime_processor
        self.display_window = "License Plate Recognition - Live"
        
    def start_viewer(self, camera_index: int = 0):
        """ì›¹ìº  ë·°ì–´ ì‹œì‘"""
        # ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œì‘
        if not self.realtime_processor.start_camera_processing(camera_index):
            logger.error("ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œì‘ ì‹¤íŒ¨")
            return
        
        # OpenCV ìœˆë„ìš° ìƒì„±
        cv2.namedWindow(self.display_window, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.display_window, 1280, 720)
        
        logger.info("ì›¹ìº  ë·°ì–´ ì‹œì‘. 'q' í‚¤ë¥¼ ëˆŒëŸ¬ ì¢…ë£Œí•˜ì„¸ìš”.")
        
        last_update = time.time()
        
        while True:
            # ìµœì‹  ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            result = self.realtime_processor.get_latest_result(timeout=0.1)
            
            if result:
                frame = result['frame']
                detection = result['detection']
                
                # í†µê³„ ì •ë³´ ì˜¤ë²„ë ˆì´
                stats = self.realtime_processor.get_statistics()
                self._draw_overlay(frame, stats, detection)
                
                cv2.imshow(self.display_window, frame)
                last_update = time.time()
            
            # í‚¤ë³´ë“œ ì…ë ¥ ì²´í¬
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):  # ìŠ¤í¬ë¦°ìƒ·
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                screenshot_path = f"screenshot_{timestamp}.jpg"
                if result:
                    cv2.imwrite(screenshot_path, result['frame'])
                    logger.info(f"ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {screenshot_path}")
            elif key == ord(' '):  # ì¼ì‹œì •ì§€/ì¬ê°œ
                if self.realtime_processor.is_running:
                    self.realtime_processor.stop_processing()
                    logger.info("ì²˜ë¦¬ ì¼ì‹œì •ì§€")
                else:
                    self.realtime_processor.start_camera_processing(camera_index)
                    logger.info("ì²˜ë¦¬ ì¬ê°œ")
        
        # ì •ë¦¬
        self.realtime_processor.stop_processing()
        cv2.destroyAllWindows()
        logger.info("ì›¹ìº  ë·°ì–´ ì¢…ë£Œ")
    
    def _draw_overlay(self, frame: np.ndarray, stats: Dict[str, Any], detection: Optional[PlateDetection]):
        """í”„ë ˆì„ì— í†µê³„ ì •ë³´ ì˜¤ë²„ë ˆì´"""
        height, width = frame.shape[:2]
        
        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (400, 150), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # í…ìŠ¤íŠ¸ ì •ë³´
        texts = [
            f"FPS: {stats.get('fps', 0):.1f}",
            f"Detections: {stats.get('detection_count', 0)}",
            f"Detection Rate: {stats.get('detection_rate', 0):.1f}/min",
            f"Avg Process Time: {stats.get('avg_processing_time', 0):.3f}s"
        ]
        
        if detection:
            texts.append(f"Last Detected: {detection.plate_number}")
        
        y_offset = 30
        for text in texts:
            cv2.putText(frame, text, (20, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
            y_offset += 25
        
        # ì œì–´ ì•ˆë‚´
        controls = [
            "Controls:",
            "Q - Quit",
            "S - Screenshot", 
            "SPACE - Pause/Resume"
        ]
        
        y_offset = height - 100
        for control in controls:
            cv2.putText(frame, control, (20, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            y_offset += 20

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì›¹ìº  ë·°ì–´ ë°ëª¨"""
    try:
        from license_plate_recognizer import YOLOv8LicensePlateRecognizer
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        recognizer = YOLOv8LicensePlateRecognizer()
        db_manager = DatabaseManager()
        realtime_processor = RealTimeProcessor(recognizer, db_manager)
        
        # íƒì§€ ì½œë°± ì„¤ì •
        def on_detection(detection: PlateDetection, frame: np.ndarray):
            print(f"ğŸš— íƒì§€ë¨: {detection.plate_number} (ì‹ ë¢°ë„: {detection.confidence:.3f})")
        
        realtime_processor.set_detection_callback(on_detection)
        
        # ì›¹ìº  ë·°ì–´ ì‹œì‘
        viewer = WebcamViewer(realtime_processor)
        viewer.start_viewer(camera_index=0)
        
    except KeyboardInterrupt:
        logger.info("ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        logger.error(f"ì‹¤ì‹œê°„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    main()